Hi! I’m Anish Kalra, a Computer Science major with a Business minor at UT Austin. I’m drawn to software engineering, AI/ML, and startups, and I’m looking ahead to Summer 2026 internships. At the core of everything I do is my work ethic—I pride myself on being one of the hardest-working people I know. I’ve spent countless sleepless nights, grinding until sunrise, pushing through insanely long sessions and all-nighters because I care deeply about the craft. For me, resilience isn’t just about bouncing back when things are hard; it’s about pushing forward when others would have stopped.

At UT, my education has blended technical rigor with human-centered curiosity. I’ve taken courses in Operating Systems, Computer Architecture, Machine Learning, Robotics, Data Structures & Algorithms, Discrete Math, Linear Algebra, Multi-Variable Calculus, and Probability. My favorite, though, has been AI in Storytelling, where we studied how every human interaction can be understood as a story and how AI will reshape storytelling when it reaches mass adoption. In Robotics, I worked with creating state-of-the-art pressure-sensitive robotic arms, while Operating Systems and Computer Architecture taught me the discipline of deep, low-level work. Beyond the classroom, I serve as Engineering Chair for Texas Convergent, a Team Lead for Texas Guadaloop, and a CS Pod Mentor helping freshmen navigate academics and career prep.

My proudest technical journey has been co-founding HeyEVA, where I serve as CTO. HeyEVA is more than an app—it’s an agentic AI assistant designed to empower less tech savvy adults to navigate their phones safely and independently. What makes it special is that it’s building something no one has ever done before: real-time, AI-powered screen sharing guidance that surpasses anything Siri, Gemini, or Alexa can offer. The technical backbone is complex: I wrote a custom algorithm that can accurately detect when a user has completed an action and automatically trigger the next step in the guidance pipeline. I integrated low-latency real-time WebSocket-based speech-to-text and text-to-speech systems so Eva feels responsive and human. On the backend, I deployed everything on AWS, designed scalable Postgres databases, and built a cloud-native architecture that can handle continuous interaction. And of course, all of this is framed around the concept of agentic AI, where Eva doesn’t just react—she takes initiative to guide users. What makes this even more exciting is that our competition includes startups led by engineers with 20+ years of experience at Apple and Google, yet HeyEVA, built by me as a college student, has already been beta tested in 15+ independent living facilities, has won over $15,000 in competitions, and is a Top 12 finalist for an upcoming $100,000 national pitch competition. Many of those victories came from the sheer hours of work I’ve poured in—pulling nights that end at 7am, driven by the belief that what we’re building is truly groundbreaking.

At Anvil Labs, where I most recently interned in New York as a software engineer, I got to push cutting-edge infrastructure technology forward while learning directly under the founder—who had previously been a founding engineer at Stripe and personally took me under his wing. Anvil’s mission is to use autonomous drone fleets to capture massive datasets of construction and military sites and transform them into actionable 3D models for monitoring, safety, and planning. My role was to engineer a significant chunk of the data pipeline required to handle this scale. I worked with Python + CesiumJS to stitch imagery into interactive 3D reconstructions and heatmaps, then designed and deployed backend APIs with FastAPI and frontend dashboards in React.js that lets users seamlessly view and annotate their large-scale site models. On the infrastructure side, I built AWS Lambda + S3–based serverless pipelines that automated ingestion and preprocessing of thousands of drone images, scaling for millions of files. I also created an AI agent with OpenAI APIs that could parse messy, unstructured client requests into structured workflows, cutting turnaround and order finalizations from days to hours. The technical challenge—optimizing pipelines for both performance and cost while ensuring robustness at scale—was intense, but working 14-hour days alongside a Stripe veteran gave me invaluable exposure to what “world-class engineering” feels like.

This past summer, I also worked on Uber’s LLM training pipelines as a contractor, where I wrote Python scripts to preprocess audio and text datasets. It was a smaller role but gave me a first-hand look into how small data tweaks can cascade into massive impacts during training. At UT, through Texas Convergent, I rebuilt Hornslink, the student organization platform used by 50,000+ students. This was a deeply technical full-stack project: I helped architect the system with React Native for mobile and Flask on the backend, implemented secure authentication and persistent data flows, and designed APIs that supported high-volume queries from thousands of students simultaneously. To seed the database, I wrote large-scale Selenium scrapers that pulled structured data from 3,000+ clubs, which then fed into an ML-powered personalization layer to recommend organizations to students. The project was essentially a ground-up rebuild of an enterprise-scale platform, and it gave me valuable experience in managing data pipelines and scaling services. At Texas Guadaloop, I’ve supported Hyperloop R&D by building internal tools for LLM integration and data tracking to improve research workflows. And at UT Dallas, I worked as a research intern in the Embedded Machine Learning Lab, which was before the GPT and LLM craze had even started. Back then, we were experimenting with ways to make models more sample-efficient: I developed real-time noise generation algorithms that pre-trained generative image models at 0.03 seconds per frame, enabling faster convergence. I also processed and vectorized over 200 clinical reports with RAG + NLP pipelines, building some of the earliest prototypes of healthcare-specific LLM architectures before such ideas were mainstream. Looking back now, it feels like we were laying bricks for trends that would explode only a year later.

On the side, I’ve built several projects that combine my technical skills with personal passions. EcoReviveTX was a full-stack web app built with React.js, Flask, and C extensions for performance-critical ML predictions, in partnership with the Texas Parks and Wildlife Department to support ecological restoration efforts. I initiated it by cold-emailing them because of my love for wildlife. AI Marketing Agent was a Next.js + Python platform that automated lead generation: it identified Instagram client profiles, extracted emails, and generated targeted outreach campaigns using LLM web search + data scraping pipelines. The system achieved conversion rates twice the industry average, and eventually a company approached me with interest in acquiring it. SafeStep was a mobile app I built with React Native, TypeScript, and the Google Maps API, designed to help tourists and residents find safer walking routes via real-time geospatial alerts based on live data. Finally, StatSwish was an NBA analytics platform built with React.js, Spring Boot, and ML pipelines, where I engineered data ingestion workflows to track over 700 players across 16,000+ stats. The system supported advanced filters, game prediction models, and interactive dashboards for fans and analysts alike. Each of these projects not only sharpened my technical toolkit but also gave me firsthand experience in full-stack product development, scaling data systems, and blending AI with real-world utility.

In leadership, I’ve had the chance to serve as Engineering Chair for Texas Convergent, where I lead all technical initiatives for UT’s largest CS org and am the youngest officer on the board. I’m also a CS Pod Mentor, where I was selected as 1 of 30 out of nearly 500 applicants to mentor freshmen in computer science, helping them adjust academically and prepare for their careers. Outside of tech, I balance things with Comedy & Improv Club, intramural basketball, and gardening.

I’ve been lucky enough to pick up some awards along the way, from being a co-author of the Guinness World Record for the largest book ever published (11 feet tall, 496 pounds) to winning over $15,000 in pitch competitions and being a finalist in a $100,000 national pitch competition.

Technically, I’m fluent across the stack. I program in Python, Java, TypeScript, JavaScript, SQL, C, Swift, HTML, CSS/SCSS, Assembly, and MATLAB. I’ve built with React, React Native, FastAPI, Flask, Tailwind, Spring Boot, Django, jQuery, and Docker. I work comfortably in Git, Linux, Ubuntu, PostgreSQL, AWS, and GCP. And for ML, I’ve worked with TensorFlow, Keras, OpenCV, Scikit-Learn, NLTK, Selenium, Beautiful Soup, NumPy, and Pandas.